{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique ids for images in a directory\n",
    "import os, sys, numpy, glob\n",
    "filtered_dir = '/data11/mc48/renders/mohit/inpaint_4f_passthrough'\n",
    "files = sorted(glob.glob(os.path.join(filtered_dir, '*/*.jpg')))\n",
    "\n",
    "img_ids = []\n",
    "for file in files:\n",
    "    ids = file.split('/')\n",
    "    unique_id = ids[-2] + '_' + ids[-1]\n",
    "    img_ids.append(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new file with only unique ids which match preset data\n",
    "sampled_path = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths.txt'\n",
    "indices_path = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices.txt'\n",
    "paths = open(sampled_path, 'r').read().split('\\n')[:-1]\n",
    "indices = open(indices_path, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "new_path = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_filtered.txt'\n",
    "new_indices = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_filtered.txt'\n",
    "count = {}\n",
    "for i in range(len(paths)):\n",
    "    ids = paths[i].split('/')\n",
    "    unique_id = ids[-2] + '_' + ids[-1].split('_')[-1]\n",
    "    if unique_id not in count:\n",
    "        count[unique_id] = 0\n",
    "    else:\n",
    "        count[unique_id] += 1\n",
    "    if unique_id in img_ids and count[unique_id]==0:\n",
    "        count[unique_id] += 1\n",
    "        with open(new_path, 'a') as f:\n",
    "            f.write(paths[i] + '\\n')\n",
    "        with open(new_indices, 'a') as f:\n",
    "            f.write(indices[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for repeats\n",
    "og_indices = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices.txt'\n",
    "new_indices = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_2.txt'\n",
    "new_img_paths = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_2.txt'\n",
    "og_indices = open(og_indices, 'r').read().split('\\n')[:-1]\n",
    "new_indices = open(new_indices, 'r').read().split('\\n')[:-1]\n",
    "new_img_paths = open(new_img_paths, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "repeat = 0\n",
    "unique_indices, unique_img_paths = [], []\n",
    "for idx in range(len(new_indices)):\n",
    "    if new_indices[idx] in og_indices:\n",
    "        repeat += 1\n",
    "    else:\n",
    "        unique_indices.append(new_indices[idx])\n",
    "        unique_img_paths.append(new_img_paths[idx])\n",
    "print (repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique ids for images in a directory\n",
    "import os, sys, glob\n",
    "import numpy as np\n",
    "img_dir = '/data11/mc48/renders/mohit/inpaint_4f_best_passthrough'\n",
    "img_paths = sorted(glob.glob(os.path.join(img_dir, '*/*/*/*.png')))\n",
    "\n",
    "img_ids = []\n",
    "for img in img_paths:\n",
    "    name = img.split('/')\n",
    "    unique_id = name[-2] + '_' + name[-1].split('.')[0]\n",
    "    img_ids.append(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare and find matches & anomalies\n",
    "new_path = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_2_hand_filtered.txt'\n",
    "new_indices = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_2_hand_filtered.txt'\n",
    "paths = open(new_path, 'r').read().split('\\n')[:-1]\n",
    "indices = open(new_indices, 'r').read().split('\\n')[:-1]\n",
    "count = {}\n",
    "for i in range(len(paths)):\n",
    "    ids = paths[i].split('/')\n",
    "    unique_id = ids[-2] + '_' + ids[-1].split('.')[0]\n",
    "    # print (unique_id)\n",
    "    # break\n",
    "    if unique_id not in count:\n",
    "        count[unique_id] = 0\n",
    "    else:\n",
    "        count[unique_id] += 1\n",
    "    if unique_id in img_ids and count[unique_id]==0:\n",
    "        count[unique_id] += 1\n",
    "        # with open(new_path, 'a') as f:\n",
    "        #     f.write(paths[i] + '\\n')\n",
    "        # with open(new_indices, 'a') as f:\n",
    "        #     f.write(indices[i] + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine existing files\n",
    "img_path_50k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_filtered.txt'\n",
    "indices_path_50k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_filtered.txt'\n",
    "img_path_50k_more = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_2_filtered.txt'\n",
    "indices_path_50k_more = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_2_filtered.txt'\n",
    "img_path_50k = open(img_path_50k, 'r').read().split('\\n')[:-1]\n",
    "indices_path_50k = open(indices_path_50k, 'r').read().split('\\n')[:-1]\n",
    "img_path_50k_more = open(img_path_50k_more, 'r').read().split('\\n')[:-1]\n",
    "indices_path_50k_more = open(indices_path_50k_more, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "img_path_100k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_100k_filtered.txt'\n",
    "indices_path_100k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_100k_filtered.txt'\n",
    "for i in range(len(img_path_50k)):\n",
    "    with open(img_path_100k, 'a') as f:\n",
    "        f.write(img_path_50k[i] + '\\n')\n",
    "    with open(indices_path_100k, 'a') as f:\n",
    "        f.write(indices_path_50k[i] + '\\n')\n",
    "for i in range(len(img_path_50k_more)):\n",
    "    with open(img_path_100k, 'a') as f:\n",
    "        f.write(img_path_50k_more[i] + '\\n')\n",
    "    with open(indices_path_100k, 'a') as f:\n",
    "        f.write(indices_path_50k_more[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new 50k filtered images\n",
    "img_path_50k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_hand_filtered.txt'\n",
    "indices_50k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_hand_filtered.txt'\n",
    "img_path_100k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_100k_hand_filtered.txt'\n",
    "indices_100k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_100k_hand_filtered.txt'\n",
    "img_path_50k = open(img_path_50k, 'r').read().split('\\n')[:-1]\n",
    "indices_50k = open(indices_50k, 'r').read().split('\\n')[:-1]\n",
    "img_path_100k = open(img_path_100k, 'r').read().split('\\n')[:-1]\n",
    "indices_100k = open(indices_100k, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "new_img_path_50k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_50k_new_hand_filtered.txt'\n",
    "new_indices_50k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_50k_new_hand_filtered.txt'\n",
    "novel = 0\n",
    "for i in range(len(img_path_100k)):\n",
    "    if img_path_100k[i] not in img_path_50k:\n",
    "        novel += 1\n",
    "        with open(new_img_path_50k, 'a') as f:\n",
    "            f.write(img_path_100k[i] + '\\n')\n",
    "        with open(new_indices_50k, 'a') as f:\n",
    "            f.write(indices_100k[i] + '\\n')\n",
    "print (novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575\n",
      "50000 97525\n"
     ]
    }
   ],
   "source": [
    "img_path_50k_more = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_50k_more.txt'\n",
    "indices_50k_more = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_50k_more.txt'\n",
    "img_path_50k_more = open(img_path_50k_more, 'r').read().split('\\n')[:-1]\n",
    "indices_50k_more = open(indices_50k_more, 'r').read().split('\\n')[:-1]\n",
    "img_path_50k_more_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_50k_more_filtered.txt'\n",
    "indices_50k_more_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_50k_more_filtered.txt'\n",
    "repeat = 0\n",
    "for i, path in enumerate(img_path_50k_more):\n",
    "    if path in img_path_100k:\n",
    "        repeat += 1\n",
    "        continue\n",
    "    with open(img_path_50k_more_filtered, 'a') as f:\n",
    "        f.write(path + '\\n')\n",
    "    with open(indices_50k_more_filtered, 'a') as f:\n",
    "        f.write(indices_50k_more[i] + '\\n')\n",
    "print (repeat)\n",
    "print (len(img_path_50k_more), len(img_path_100k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_100k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_100k_hand_filtered.txt'\n",
    "indices_100k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_100k_hand_filtered.txt'\n",
    "img_50k_more = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_50k_more_filtered.txt'\n",
    "indices_50k_more = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_50k_more_filtered.txt'\n",
    "img_150k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_150k_hand_filtered.txt'\n",
    "indices_150k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_150k_hand_filtered.txt'\n",
    "img_100k = open(img_100k, 'r').read().split('\\n')[:-1]\n",
    "indices_100k = open(indices_100k, 'r').read().split('\\n')[:-1]\n",
    "img_50k_more = open(img_50k_more, 'r').read().split('\\n')[:-1]\n",
    "indices_50k_more = open(indices_50k_more, 'r').read().split('\\n')[:-1]\n",
    "\n",
    "for i in range(len(img_100k)):\n",
    "    with open(img_150k, 'a') as f:\n",
    "        f.write(img_100k[i] + '\\n')\n",
    "    with open(indices_150k, 'a') as f:\n",
    "        f.write(indices_100k[i] + '\\n')\n",
    "for i in range(len(img_50k_more)):\n",
    "    with open(img_150k, 'a') as f:\n",
    "        f.write(img_50k_more[i] + '\\n')\n",
    "    with open(indices_150k, 'a') as f:\n",
    "        f.write(indices_50k_more[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 144651 144650\n"
     ]
    }
   ],
   "source": [
    "img_150k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_150k_hand_invalid.txt'\n",
    "indices_150k = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_150k_hand_invalid.txt'\n",
    "img_150k_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_150k_hand_filtered.txt'\n",
    "indices_150k_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_150k_hand_filtered.txt'\n",
    "img_150k = open(img_150k, 'r').read().split('\\n')[:-1]\n",
    "indices_150k = open(indices_150k, 'r').read().split('\\n')[:-1]\n",
    "invalid = ['P15_02_frame_0000037020', 'P15_13_frame_0000020443']\n",
    "valid = 0\n",
    "anomaly = []\n",
    "for i, img in enumerate(img_150k):\n",
    "    name = img.split('/')\n",
    "    unique_id = name[-2] + '_' + name[-1].split('.')[0]\n",
    "    if unique_id in invalid:\n",
    "        continue\n",
    "    if unique_id not in img_ids:\n",
    "        anomaly.append(img)\n",
    "    else:\n",
    "        valid += 1\n",
    "        with open(img_150k_filtered, 'a') as f:\n",
    "            f.write(img + '\\n')\n",
    "        with open(indices_150k_filtered, 'a') as f:\n",
    "            f.write(indices_150k[i] + '\\n')\n",
    "print (len(anomaly), len(img_150k), valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 144650\n"
     ]
    }
   ],
   "source": [
    "img_150k_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_150k_hand_filtered.txt'\n",
    "indices_150k_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_150k_hand_filtered.txt'\n",
    "img_150k_filtered = open(img_150k_filtered, 'r').read().split('\\n')[:-1]\n",
    "indices_150k_filtered = open(indices_150k_filtered, 'r').read().split('\\n')[:-1]\n",
    "img_1k_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_img_paths_1k_hand_filtered.txt'\n",
    "indices_1k_filtered = '/home/adityap9/projects/hands-as-probes/ACP/debug/sampled_indices_1k_hand_filtered.txt'\n",
    "import random\n",
    "sampled_idx = random.sample(range(len(img_150k_filtered)), 1000)\n",
    "for idx in sampled_idx:\n",
    "    with open(img_1k_filtered, 'a') as f:\n",
    "        f.write(img_150k_filtered[idx] + '\\n')\n",
    "    with open(indices_1k_filtered, 'a') as f:\n",
    "        f.write(indices_150k_filtered[idx] + '\\n')\n",
    "print (len(sampled_idx), len(img_150k_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, json, pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract past frames from videos for MOW data\n",
    "mow_videos = '/data11/adityap9/100_doh/videos'\n",
    "video_paths = sorted(glob.glob(os.path.join(mow_videos, '*_frames/*')))\n",
    "videos = {}\n",
    "videos_frames = {}\n",
    "for video in video_paths:\n",
    "    video_id = video.split('/')[-1]\n",
    "    videos[video_id] = sorted(glob.glob(os.path.join(video, '*.jpg')))\n",
    "    videos_frames[video_id] = sorted(os.listdir(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(videos.keys())\n",
    "'Ju4nMfNx80I' in videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom split of images with available videos\n",
    "mow_path = '/home/adityap9/projects/MOW/data/mow/images'\n",
    "mow_imgs = sorted(glob.glob(os.path.join(mow_path, '*.jpg')))\n",
    "required_imgs = {}\n",
    "for idx, img in enumerate(mow_imgs):\n",
    "    name = img.split('/')[-1]\n",
    "    video_id = name[-27:-16]\n",
    "    frame_id = name[-15:]\n",
    "    frame_num = int(name[-10:-4])\n",
    "    if video_id not in frame2duration:\n",
    "        continue\n",
    "    frame_list = videos_frames[video_id]\n",
    "    frames_full = videos[video_id]\n",
    "    duration = frame2duration[video_id]\n",
    "    required_num = int(frame_num*2/duration)\n",
    "    required_id = 'frame'+str(required_num).zfill(6)+'.jpg'\n",
    "    curr_index = frame_list.index(required_id)\n",
    "    # print (img)\n",
    "    # print (video_id, frame_id, frame_num, duration, required_num, required_id, curr_index)\n",
    "    # if idx==5: break\n",
    "    if curr_index-4>=0:\n",
    "        required_imgs[img] = frames_full[curr_index-4:curr_index]\n",
    "\n",
    "# save the required images\n",
    "save_path = 'ACP/debug/mow_all_data_v2.json'\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(required_imgs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mow split with images from above videos\n",
    "import pickle\n",
    "mow_split = '/data01/adityap9/datasets/IHOI/cache/mow_custom_test_split/mow_test.pkl'\n",
    "mow_split = pickle.load(open(mow_split, 'rb'))\n",
    "\n",
    "valid_ids = []\n",
    "for k in required_imgs.keys():\n",
    "    name = k.split('/')[-1].split('.')[0]\n",
    "    valid_ids.append(name)\n",
    "relevant_split = {}\n",
    "for k in mow_split.keys():\n",
    "    relevant_split[k] = []\n",
    "for idx in range(len(mow_split['index'])):\n",
    "    if mow_split['index'][idx] in valid_ids:\n",
    "        for k in mow_split.keys():\n",
    "            relevant_split[k].append(mow_split[k][idx])\n",
    "# save_file = '/data01/adityap9/datasets/IHOI/cache/mow_custom_test_split/mow_test_matthew.pkl'\n",
    "# pickle.dump(relevant_split, open(save_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    }
   ],
   "source": [
    "# extract video information from 100DOH dataset\n",
    "path = '/data11/adityap9/100_doh/file/meta_100DOH_video.txt'\n",
    "lines = open(path, 'r').read().split('\\n')[:-1]\n",
    "video2frames = {}\n",
    "video2count = {}\n",
    "for i in range(1, len(lines)):\n",
    "    ids = lines[i].split()\n",
    "    video_id = ids[0]\n",
    "    num_frames = int(ids[5])\n",
    "    if video_id not in video2frames:\n",
    "        video2frames[video_id] = [num_frames]\n",
    "    else:\n",
    "        video2frames[video_id].append(num_frames)\n",
    "    if video_id not in video2count:\n",
    "        video2count[video_id] = 1\n",
    "    else:\n",
    "        video2count[video_id] += 1\n",
    "\n",
    "repeats = []\n",
    "for k, v in video2count.items():\n",
    "    if v>1:\n",
    "        repeats.append(k)\n",
    "print (len(repeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ['tlTtHu8Noss', 'UsYE9e4nQLs', 'gSlmIS1dZpo', 'N8FGdSSIWho', '2TLgO7iJ2-s', '32bMlq-9JUc', 'b8BmO_F7HJU', 'nAF2wpD8fi4']\n",
      "1 ['r-7IvAnDCDE']\n"
     ]
    }
   ],
   "source": [
    "# check repeat video ids for consistent lengths, 1 video id has 2 different lengths: 'r-7IvAnDCDE' (not present in MOW)\n",
    "import json\n",
    "valid_path = 'ACP/debug/mow_all_data.json'\n",
    "valid_data = json.load(open(valid_path, 'r'))\n",
    "\n",
    "video_ids = list(valid_data.keys())\n",
    "anomaly = []\n",
    "for video in video_ids:\n",
    "    video_id = video[-27:-16]\n",
    "    if video_id in repeats:\n",
    "        anomaly.append(video_id)\n",
    "print (len(anomaly), anomaly)\n",
    "\n",
    "check = []\n",
    "for k, v in video2count.items():\n",
    "    if v>1:\n",
    "        if len(np.unique(video2frames[k])) > 1:\n",
    "            check.append(k)\n",
    "print (len(check), check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_list = list(videos_frames.keys())\n",
    "frame2duration = {}\n",
    "for i in range(1, len(lines)):\n",
    "    ids = lines[i].split()\n",
    "    video_id = ids[0]\n",
    "    duration = float(ids[2])\n",
    "    num_frames = int(ids[5])\n",
    "    frame_rate = int(ids[4].split('/')[0]) / int(ids[4].split('/')[1])\n",
    "    if video_id not in videos:\n",
    "        continue\n",
    "    num_saved_frames = len(videos[video_id])\n",
    "    time_per_frame = duration / num_saved_frames\n",
    "    frame2duration[video_id] = time_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frame2duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if any of the train sequences didn't get inpainted\n",
    "inpaint_path = '/data11/mc48/renders/ho3d_train/inpaint_4f_best/'\n",
    "inpaint_imgs = sorted(glob.glob(os.path.join(inpaint_path, '*/*/rgb/*.jpg')))\n",
    "valid_ids = []\n",
    "for img in inpaint_imgs:\n",
    "    name = path.split('/')\n",
    "    idx = '{}_{}_{}'.format(name[-4], name[-3], name[-1].split('.')[0])\n",
    "    valid_ids.append(idx)\n",
    "\n",
    "ho3d = 'ACP/debug/ho3d_train_sequences.json'\n",
    "ho3d = json.load(open(ho3d, 'r'))\n",
    "all_ids = list(ho3d.keys())\n",
    "anomaly = []\n",
    "for idx in all_ids:\n",
    "    name = idx.split('/')\n",
    "    unique_id = '{}_{}_{}'.format(name[-4], name[-3], name[-1].split('.')[0])\n",
    "    if unique_id not in valid_ids:\n",
    "        anomaly.append(idx)\n",
    "print (len(anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract past 4 frames in the format required for Matthew's inpainting model\n",
    "ho3d_eval_path = '/data01/adityap9/datasets/IHOI/cache/ho3d_vid_train_plus.pkl'\n",
    "ho3d_eval = pickle.load(open(ho3d_eval_path, 'rb'))\n",
    "\n",
    "ho3d_dir = '/data01/adityap9/datasets/IHOI/ho3d'\n",
    "image_dir = os.path.join(ho3d_dir, '{}', '{}', 'rgb', '{}.jpg')\n",
    "interval = 30*36/50\n",
    "sequence = {}\n",
    "anomaly = []\n",
    "for i in range(0, len(ho3d_eval['index']), 1):\n",
    "    idx = ho3d_eval['index'][i]\n",
    "    img_path = image_dir.format(*idx)\n",
    "    frame_num = int(idx[2])\n",
    "    # total_frames = len(glob.glob(os.path.join(ho3d_dir, idx[0], idx[1], 'rgb/*.jpg')))\n",
    "    if frame_num - int(interval*3) > 0:\n",
    "        sequence[img_path] = []\n",
    "        for j in range(3):\n",
    "            num = frame_num - int(interval*(j+1))\n",
    "            prev_path = image_dir.format(idx[0], idx[1], str(num).zfill(4))\n",
    "            if not os.path.exists(prev_path):\n",
    "                anomaly.append(img_path)\n",
    "            sequence[img_path].append(prev_path)\n",
    "# save sequences in json format\n",
    "save_path = 'ACP/debug/ho3d_train_sequences.json'\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(sequence, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = '/data01/adityap9/datasets/IHOI/cache/multiview_balanced_split/ho3d_vid_train_plus.pkl'\n",
    "train_split = pickle.load(open(train_split, 'rb'))\n",
    "val_split = '/data01/adityap9/datasets/IHOI/cache/multiview_balanced_split/ho3d_vid_val_plus.pkl'\n",
    "val_split = pickle.load(open(val_split, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56363, 10745)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10745\n",
      "59661 59661\n",
      "8493\n"
     ]
    }
   ],
   "source": [
    "# create ho3d test split for neurips submission\n",
    "import pickle\n",
    "ho3d_split = '/data01/adityap9/datasets/IHOI/cache/balanced_split/ho3d_vid_val_plus.pkl'\n",
    "ho3d_split = pickle.load(open(ho3d_split, 'rb'))\n",
    "print (len(ho3d_split['index']))\n",
    "\n",
    "valid_ho3d = 'ACP/debug/ho3d_train_sequences.json'\n",
    "valid_ho3d = json.load(open(valid_ho3d, 'r'))\n",
    "valid = list(valid_ho3d.keys())\n",
    "valid_ids = []\n",
    "for path in valid:\n",
    "    name = path.split('/')\n",
    "    idx = '{}_{}_{}'.format(name[-4], name[-3], name[-1].split('.')[0])\n",
    "    valid_ids.append(idx)\n",
    "print (len(valid), len(valid_ids))\n",
    "\n",
    "test_dict = {}\n",
    "for i in range(len(ho3d_split['index'])):\n",
    "    name = ho3d_split['index'][i]\n",
    "    idx = '{}_{}_{}'.format(name[0], name[1], name[2])\n",
    "    if idx in valid_ids:\n",
    "        for k in ho3d_split.keys():\n",
    "            if k not in test_dict:\n",
    "                test_dict[k] = []\n",
    "            test_dict[k].append(ho3d_split[k][i])\n",
    "print (len(test_dict['index']))\n",
    "\n",
    "# dump test dict in pickle format\n",
    "# save_path = '/data01/adityap9/datasets/IHOI/cache/ho3d_vid3fps_test_plus_neurips.pkl'\n",
    "# pickle.dump(test_dict, open(save_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on view\n",
    "import pickle\n",
    "ho3d_train = '/data01/adityap9/datasets/IHOI/cache/ho3d_neurips_split/ho3d_vid_train_plus.pkl'\n",
    "ho3d_train = pickle.load(open(ho3d_train, 'rb'))\n",
    "ho3d_val = '/data01/adityap9/datasets/IHOI/cache/ho3d_neurips_split/ho3d_vid_val_plus.pkl'\n",
    "ho3d_val = pickle.load(open(ho3d_val, 'rb'))\n",
    "\n",
    "def get_view_count(split):    \n",
    "    all_ids = list(split['index'])\n",
    "    views_count = {}\n",
    "    for idx in all_ids:\n",
    "        sub = idx[1]\n",
    "        # extract digits from subject name\n",
    "        view = ''.join([i for i in sub if i.isdigit()])\n",
    "        if view not in views_count:\n",
    "            views_count[view] = 0\n",
    "        else:\n",
    "            views_count[view] += 1\n",
    "    return views_count\n",
    "\n",
    "train_count = get_view_count(train_split)\n",
    "val_count = get_view_count(val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize inpainted images\n",
    "import os.path as osp\n",
    "data_dir = '/data01/adityap9/datasets/IHOI/ho3d'\n",
    "image_dir = osp.join(data_dir, '{}', '{}', 'rgb', '{}.jpg')\n",
    "inpaint_test_dir = osp.join('/data11/mc48/renders/ho3d/inpaint_4f_best', '{}', '{}', 'rgb', '{}.jpg')\n",
    "inpaint_train_dir = osp.join('/data11/mc48/renders/ho3d_train/inpaint_4f_best', '{}', '{}', 'rgb', '{}.jpg')\n",
    "ho3d_eval = '/data01/adityap9/datasets/IHOI/cache/ho3d_neurips_split/ho3d_vid3fps_test_plus.pkl'\n",
    "ho3d_eval = pickle.load(open(ho3d_eval, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho3d_val = '/data01/adityap9/datasets/IHOI/cache/ho3d_neurips_split/ho3d_vid_val_plus.pkl'\n",
    "ho3d_val = pickle.load(open(ho3d_val, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "save_dir = '/data11/adityap9/ihoi/debug/_matthew_neurips/debug/viz/inpaint_val'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for j in range(0,len(ho3d_val['index']), 10):\n",
    "    idx = ho3d_val['index'][j]\n",
    "    # load images\n",
    "    img = Image.open(image_dir.format(*idx))\n",
    "    inpaint_img = Image.open(inpaint_train_dir.format(*idx))\n",
    "    # resize inpaint img\n",
    "    inpaint_img = inpaint_img.resize((min(img.size), min(img.size)))\n",
    "    # visualize side by side\n",
    "    img = np.array(img)\n",
    "    inpaint_img = np.array(inpaint_img)\n",
    "    img = np.concatenate((img, inpaint_img), axis=1)\n",
    "    img = Image.fromarray(img)\n",
    "    # save image\n",
    "    save_path = osp.join(save_dir, '{}_{}_{}.jpg'.format(idx[0], idx[1], idx[2]))\n",
    "    img.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8493"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create val split from ho3d by holding out '1' view\n",
    "ho3d_path = '/data01/adityap9/datasets/IHOI/cache/ho3d_neurips_split/ho3d_vid3fps_test_plus_neurips.pkl'\n",
    "ho3d = pickle.load(open(ho3d_path, 'rb'))\n",
    "\n",
    "all_views = []\n",
    "val_dict = {}\n",
    "for k in ho3d.keys():\n",
    "    val_dict[k] = []\n",
    "for j, idx in enumerate(ho3d['index']):\n",
    "    pid = idx[1]\n",
    "    # extract digits from string\n",
    "    view = ''.join(filter(str.isdigit, pid))\n",
    "    all_views.append(view)\n",
    "    # if j%100==0: print (idx, view)\n",
    "    if view == '10':\n",
    "        for k in ho3d.keys():\n",
    "            val_dict[k].append(ho3d[k][j])\n",
    "\n",
    "# ho3d_val_path = '/data01/adityap9/datasets/IHOI/cache/ho3d_neurips_split/ho3d_vid3fps_test_plus_neurips_v10.pkl'\n",
    "# pickle.dump(val_dict, open(ho3d_val_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factored is better f5 in 350 out of 1190\n",
      "factored is better f10 in 335 out of 1190\n",
      "factored is better cd in 259 out of 1190\n"
     ]
    }
   ],
   "source": [
    "# compare metrics 1:1\n",
    "og_metrics_txt = '/data11/adityap9/ihoi/debug/_matthew_neurips/eval_og_obman_ho3d/rep/ho3d/default/f1_num.txt'\n",
    "factored_cat_metrics_txt = '/data11/adityap9/ihoi/debug/_matthew_neurips/eval_og_factored_obman_ho3d/rep/ho3d/default/f1_num.txt'\n",
    "\n",
    "def extract_metrics(metrics_file):\n",
    "    with open(metrics_file, 'rb') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    total_size = len(lines)\n",
    "    f5s, f10s, cds, ids = [], [], [], []\n",
    "    for j, metric in enumerate(lines):\n",
    "        if j == 0 or j >= total_size-1:\n",
    "            continue\n",
    "        scores = metric.decode('UTF-8').strip('\\n')\n",
    "        idx, f5, f10, cd = scores.split(',')\n",
    "        f5s.append(float(f5))\n",
    "        f10s.append(float(f10))\n",
    "        cds.append(float(cd))\n",
    "        ids.append(int(idx))\n",
    "    return f5s, f10s, cds, ids\n",
    "\n",
    "og_f5s, og_f10s, og_cds, og_ids = extract_metrics(og_metrics_txt)\n",
    "factored_cat_f5s, factored_cat_f10s, factored_cat_cds, factored_cat_ids = extract_metrics(factored_cat_metrics_txt)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(og_f5s)):\n",
    "    if og_f5s[i] < factored_cat_f5s[i]:\n",
    "        cnt += 1\n",
    "print ('factored is better f5 in {} out of {}'.format(cnt, len(og_f5s)))\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(og_f10s)):\n",
    "    if og_f10s[i] < factored_cat_f10s[i]:\n",
    "        cnt += 1\n",
    "print ('factored is better f10 in {} out of {}'.format(cnt, len(og_f10s)))\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(og_cds)):\n",
    "    if og_cds[i] > factored_cat_cds[i]:\n",
    "        cnt += 1\n",
    "print ('factored is better cd in {} out of {}'.format(cnt, len(og_cds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factored is better f5 in 272 out of 1190\n",
    "# factored is better f10 in 289 out of 1190\n",
    "# factored is better cd in 474 out of 1190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_f5s = np.array(og_f5s) - np.array(factored_cat_f5s)\n",
    "diff_f10s = np.array(og_f10s) - np.array(factored_cat_f10s)\n",
    "diff_cds = np.array(og_cds) - np.array(factored_cat_cds)\n",
    "# sort by index\n",
    "diff_f5s = [(idx, f5) for idx, f5 in zip(og_ids, diff_f5s)]\n",
    "diff_f5s = sorted(diff_f5s, key=lambda x: x[1])\n",
    "diff_f10s = [(idx, f10) for idx, f10 in zip(og_ids, diff_f10s)]\n",
    "diff_f10s = sorted(diff_f10s, key=lambda x: x[1])\n",
    "diff_cds = [(idx, cd) for idx, cd in zip(og_ids, diff_cds)]\n",
    "diff_cds = sorted(diff_cds, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 50 34\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ckpt1 = 'ACP/models/EPIC-KITCHENS/SegNet_roi_hands_5k_filtered_img_only/SegNet_roi_hands_5k_filtered_img_only_seed0_best.pth'\n",
    "ckpt2 = 'ACP/models/EPIC-KITCHENS/SegNet_roi_hands_5k_filtered_img_only_val/SegNet_roi_hands_5k_filtered_img_only_val_seed0_best.pth'\n",
    "ckpt3 = 'ACP/models/EPIC-KITCHENS/SegNet_roi_hands_5k_filtered_img_only_val_fix/SegNet_roi_hands_5k_filtered_img_only_val_fix_seed0_best.pth'\n",
    "ckpt1 = torch.load(ckpt1, map_location='cpu')\n",
    "ckpt2 = torch.load(ckpt2, map_location='cpu')\n",
    "ckpt3 = torch.load(ckpt3, map_location='cpu')\n",
    "print (ckpt1['epoch'], ckpt2['epoch'], ckpt3['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi 1k\n",
    "# seed0: 29 25\n",
    "# seed5: 24 25\n",
    "# seed100: 44 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0133,  0.0150, -0.0143, -0.0228, -0.0409, -0.0429, -0.0705],\n",
       "        [ 0.0044,  0.0066,  0.0157,  0.0206,  0.0024, -0.0202, -0.0373],\n",
       "        [ 0.0222,  0.0236,  0.0162,  0.0581,  0.1021,  0.0628,  0.0526],\n",
       "        [ 0.0241,  0.0051, -0.0449, -0.0483, -0.0160,  0.0413,  0.0673],\n",
       "        [ 0.0005,  0.0286, -0.0095, -0.0552, -0.1270, -0.0757,  0.0090],\n",
       "        [ 0.0049,  0.0491,  0.0629,  0.0841,  0.0241, -0.0330, -0.0146],\n",
       "        [-0.0782, -0.0304, -0.0160,  0.0351,  0.0366,  0.0244,  0.0041]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1[k1[0]][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0137,  0.0147, -0.0153, -0.0225, -0.0405, -0.0425, -0.0701],\n",
       "        [ 0.0041,  0.0054,  0.0143,  0.0205,  0.0020, -0.0206, -0.0380],\n",
       "        [ 0.0221,  0.0229,  0.0153,  0.0584,  0.1022,  0.0627,  0.0524],\n",
       "        [ 0.0227,  0.0031, -0.0471, -0.0492, -0.0169,  0.0402,  0.0658],\n",
       "        [-0.0015,  0.0266, -0.0115, -0.0561, -0.1279, -0.0770,  0.0077],\n",
       "        [ 0.0031,  0.0471,  0.0609,  0.0837,  0.0233, -0.0340, -0.0159],\n",
       "        [-0.0805, -0.0332, -0.0191,  0.0333,  0.0342,  0.0220,  0.0016]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2[k1[0]][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c3f64143e03234e7d2c2169465794a3351ba6cf2f3531f69e92a3ecf2eaff8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
